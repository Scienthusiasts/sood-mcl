# 推理整个验证集并可视化:
# globalw val (sparsely ann)
python test.py \
--config configs_dota15/sparse_new_idea/globalw_fcos_ss_gihead_dota10_10p_wosupbranch.py \
--checkpoint log/new_sparse/1.0/globalw_burn-in-120000_ga_10per/latest.pth \
--work-dir log/eval_result \
--gpu-ids 1 \
--eval mAP \
--out log/new_sparse/1.0/globalw_burn-in-120000_ga_10per/eval_result/eval.pkl \
--get-feature-map \
--cfg-options cfg.model.pretrained=None \
--show-score-thr 0.1 \
--show-dir log/new_sparse/1.0/globalw_burn-in-120000_ga_10per/eval_result/vis_result \






# 终端输出日志重定向:
sh run.sh > log/dtbaseline/DOTA1.5/10per_denoise/global-w/joint-score-beta-2.0_burn-in-12800_orcnn-head_all-refine-loss_box-O2M-loss_detach_GA_7/terminal_log.log 2>&1
sh run.sh > log/dtbaseline/DOTA1.5/10per_denoise/global-w/joint-score-beta-2.0_burn-in-12800_GA_7/terminal_log.log 2>&1



# pytorch下载
pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118
pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117






# 如何生成partial labeled 数据集
run /data/yht/code/sood-mcl/split_data_via_list.py


# 如何修改log指标小数点保存位数
/data/yht/code/sood-mcl/mmrotate-0.3.4/mmrotate/core/evaluation/eval_map.py -> print_map_summary() -> 修改为:.4f


# 如何将precision和recall指标显示到log和tensorboard中
# TensorboardLoggerHook 会自动将 evaluate() 计算的指标记录到 TensorBoard:
/data/yht/code/sood-mcl/mmrotate-0.3.4/mmrotate/datasets/dota.py -> evaluate() 修改eval_results字典, 加上precision和recall -> 修改eval_rbbox_map()
/data/yht/code/sood-mcl/mmrotate-0.3.4/mmrotate/core/evaluation/eval_map.py -> eval_rbbox_map() -> print_map_summary()
/data/yht/code/sood-mcl/mmrotate-0.3.4/mmrotate/core/evaluation/eval_map.py -> print_map_summary() -> 在这个函数里添加recall和precision 计算指标


# 如何修改伪框筛选策略
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss.py ->添加pseudoLabelSelection(), 返回pos_mask, neg_mask, weight_mask, fg_num, S_dps
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss.py -> forward() 调用pseudoLabelSelection得到正负样本mask和S_dps等


# 将S_dps记录到log和tensorboard中
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss.py -> forward() 将S_dps作为loss的一个字段返回即可


# 如何加prototype到模型中
(1) 首先获取FPN的多尺度特征图
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py -> forward_train() 修改三个地方(teacher和student的forward_train(), 返回多尺度特征图)
/data/yht/code/sood-mcl/semi_mmrotate/models/detectors/semi_rotated_baseline_fcos.py -> forward_train() 添加return_fpn_feat字段, =True时返回FPN特征图x
(2) 返回全特征图的的类别GT, 和正样本索引
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py -> forward_train() 修改三个地方(teacher和student的forward_train())
/data/yht/code/sood-mcl/semi_mmrotate/models/detectors/semi_rotated_baseline_fcos.py -> forward_train() 这里其实无需修改, 数据流包含在logits中返回
/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py -> forward_train(), 额外返回flatten_labels
/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py -> loss(), 在返回loss字典那里额外返回flatten_labels
(3) 添加prototype类
添加/data/yht/code/sood-mcl/semi_mmrotate/models/prototype/prototype.py 
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py 导入: from .prototype.prototype import FCOSPrototype
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py -> __init__(), 添加prototype字段(也得在config文件里添加), 添加 self.prototype = FCOSPrototype(**prototype)
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py -> forward_train(), 添加prototype更新逻辑(prototype loss)
...未完待续(目前的问题, 只更新prototype不用prototype去微调特征图也会存在性能降低的bug)


# 如何在推理时返回特征图(或其他要素)
(1) 修改模型文件, 使其支持额外返回特征图
/data/yht/code/sood-mcl/semi_mmrotate/models/detectors/semi_rotated_baseline_fcos.py 重写 self.simple_test() 使其支持额外返回特征图
/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py -> self.get_bboxes() 使其支持额外回传 cls_scores, centernesses
(2) 修改测试文件, 使其支持额外返回特征图
/data/yht/code/sood-mcl/test.py -> main() 添加 --get-feature-map参数, 以及其他修改
/data/yht/code/sood-mcl/test.py -> 添加single_gpu_test() 重写 mmdet.apis.single_gpu_test
/data/yht/code/sood-mcl/test.py -> 添加vis_feature_map() 用于可视化特征图并保存


# 如何再推理时返回nms前的box
(1) 修改模型文件, 使其支持额外返回dense bbox
/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py -> self._get_bboxes_single() 额外返回 mlvl_bboxes, mlvl_scores, mlvl_centerness
/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py -> self.get_bboxes() 无需修改, 额外返回的数据包含在result_list中
(2) 修改测试文件, 使其支持额外返回dense bbox
/data/yht/code/sood-mcl/test.py -> single_gpu_test() 添加vis_dense_bboxes
/data/yht/code/sood-mcl/test.py -> 添加vis_dense_bboxes() 用于可视化dense bbox并保存


# 如何对fpn_feat实现自蒸馏
/data/yht/code/sood-mcl/semi_mmrotate/models/detectors/semi_rotated_baseline_fcos.py -> forward_train() 添加fpn_feat_grad字段, =True时保留返回FPN特征图的梯度
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py -> forward_train() stu的forward_train()设置fpn_feat_grad=True
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss.py -> forward()



# 如何取消利用prototype进行refine
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py -> forward_train() 注释 "替换teacher的score为refine的特征"下的代码
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss.py 
(1) forward() ->
t_cls_scores, t_bbox_preds, t_centernesses, t_fpn_feat, bs = self.convert_shape(teacher_logits[:-1], wo_cls_score=True) 去掉 wo_cls_score=True;  teacher_logits[:-1] 换成 teacher_logits
注释 refine_t_joint_score = teacher_logits[-1];   
删去 self.pseudoLabelSelection() 的 refine_t_joint_score参数
无监督分类损失部分 t_cls_scores 改成 t_cls_scores.sigmoid()
(2) pseudoLabelSelection() ->
删去 self.pseudoLabelSelection() 的 refine_t_joint_score参数
teacher_probs = t_cls_scores 换成 teacher_probs = t_cls_scores.sigmoid()
t_joint_scores = refine_t_joint_score.max(dim=1)[0] 换成 t_joint_scores = t_centernesses.sigmoid().reshape(-1) * t_scores


# 如何只用prototype进行当做标签筛选的权重
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss.py 
(1) forward() ->
添加  refine_t_joint_score = teacher_logits[-1];  
self.convert_shape(teacher_logits) 换成 self.convert_shape(teacher_logits[:-1])
添加 self.pseudoLabelSelection() 的 refine_t_joint_score参数
(2) pseudoLabelSelection() ->
添加 self.pseudoLabelSelection() 的 refine_t_joint_score参数
t_joint_scores = t_centernesses.sigmoid().reshape(-1) * t_scores 换成 t_joint_scores = refine_t_joint_score.max(dim=1)[0]


# 如何将高斯椭圆标签分配方法添加到模型中
(1) 添加 /data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_ga_head.py -> SemiRotatedBLFCOSGAHead
(2) 修改config配置文件


# 调整的/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_loss_old.py
rotated_dt_baseline_loss_old.py依然保留所有25.01.01之前用到的各种实验过无效的策略(比如所有伪标签筛选策略, 多尺度特征蒸馏, 基于GCA加权global_w的损失等等), 方便之后可能再次使用
rotated_dt_baseline_loss.py则删除了所有无效的策略


# 如何添加微调去噪模块(类似在一阶段上再加一个roihead变成二阶段)
(1) config文件修改
添加 /data/yht/code/sood-mcl/configs_dota15/denseteacher_baseline/denseteacher_fcos_refinehead_dota15_10p_debug.py
detector type='SemiRotatedBLFCOS' => type='SemiRotatedBLRefineFCOS'
在detector里添加roi_head=dict(...) ... (借鉴于 /data/yht/code/sood-mcl/configs_dota15/unbaisedteacher/unbaisedteacher_faster-rcnn_dota15_30p.py)
(2) detector修改
/data/yht/code/sood-mcl/semi_mmrotate/models/detectors/__init__.py 里添加 from .semi_rotated_baseline_refine_fcos import SemiRotatedBLRefineFCOS
添加 /data/yht/code/sood-mcl/semi_mmrotate/models/detectors/semi_rotated_baseline_refine_fcos.py
__init__() 修改两处
(3) /data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py
多回传 flatten_bbox_preds, flatten_angle_preds
(4) 添加 /data/yht/code/sood-mcl/semi_mmrotate/models/roi_heads/rfrcnn_roi_head.py 并注册

(5) 
在全监督部分需要获取bbox的回归结果(用于计算proposal_list), 
因此还需要 /data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py 的loss函数返回 flatten_bbox_preds 和 flatten_angle_preds
返回之后还要对回归结果进行解码得到真实图像尺度下的坐标框
其他有待修改的地方具体可以参考 /data/yht/code/sood-mcl/mmrotate-0.3.4/mmrotate/models/detectors/two_stage.py

25_1_19:
(6) 开始修改roihead部分, 最终目的是实现框的聚合(目前想到用注意力)
首先, 发现在box_head部分, 是所有box(形状是[1024, 256, 7, 7])一起进入fc层的, 可能需要再加一个分组的维度(比如变成[1024/group, group, 256, 7, 7]), 而这个分组就需要参考正负样本分配的结果.
总之, 目前需要先解决在特征层面把box分组 [1024, 256, 7, 7] -> [1024/group, group, 256, 7, 7], 后续再考虑用什么网络聚合
目前正在debuging...:
/data/yht/code/sood-mcl/semi_mmrotate/models/roi_heads/orcnn_roi_head.py -> _bbox_forward_train() 这个函数
rois = rbbox2roi([res.bboxes for res in sampling_results]) 这一行返回rois的坐标(形状是(1024, 6), [batch_ind, cx, cy, w, h, a]), 没有分组信息
其中的sampling_results是lis, 长度为bs, sampling_results[i]记录的信息如下:
<SamplingResult({
    'neg_bboxes':          记录负样本的box坐标 torch.Size([384, 5]),
    'neg_inds':            记录负样本在特征图上的索引位置, torch.Size([384]),
    'num_gts':             每张图上gt的个数, int,
    'pos_assigned_gt_inds':记录每个正样本分配给哪个GT torch.Size([128]) 这里可以得到分组信息, 但是每个gt分配到的样本数不一样,且没有置信度信息
    'pos_bboxes':          记录正样本的box坐标 torch.Size([128, 5]),
    'pos_inds':            记录负样本在特征图上的索引位置, torch.Size([128]),
    'pos_is_gt':           记录哪些正样本直接是GT的copy, 值为0或1. torch.Size([128,]),
})>

bbox_results = self._bbox_forward(x, rois) 这一行是返回box_head已经推理出的结果, 有两个bbox_results['cls_score']和bbox_results['bbox_pred'](形状分别是[1024, 17]和[1024, 5]), 没有分组信息


25_4_4:
两个文件的区别:
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_orcnnhead_loss_no_align.py
/data/yht/code/sood-mcl/semi_mmrotate/models/losses/rotated_dt_baseline_orcnnhead_loss.py
no_align的训练方式(之前都是这么训练的):
t一阶段NMS结果→训练s二阶段检测头
t二阶段检测结果→训练s一阶段头
t的proposal给s二阶段头做微调训练
no_align的训练方式:
t二阶段检测结果→训练s二阶段检测头
t二阶段检测结果→训练s一阶段头
s的proposal给s二阶段头做微调训练

但是跑完实验发现no_align的mAP反而还更高


25_4_9
偶然发现训练时, roi_head(即微调头)部分对teacher预测结果执行nms时的nms的score_thr参数对最终的结果影响很大(甚至能差一个多点):
/data/yht/code/sood-mcl/custom/utils.py: batch_nms():
        det_bboxes, det_labels, thr_idx, nms_idx = multiclass_nms_rotated(
            multi_bboxes=bboxes[i, :, :5],            # [total_box_num, 5]
            multi_scores=cls_scores_w_bg,                # [total_box_num, 16]
            score_thr=0.2,                               # 0.05
            nms={'iou_thr': 0.1},                        # {'iou_thr': 0.1}
            max_num=2000,                                # 2000
            score_factors=centerness[i, :],            # centerness[i, :] bboxes[i, :, 5]
            return_inds=True
            )

原来score_thr=0.2, 如果改成score_thr=0.1,best的mAP会降1.5个点左右


# 25 0531 加入fgclip蒸馏(Pytorch1.13.1-> 2.1.0):
1. /home/yht/.conda/envs/sood-mcl/lib/python3.9/site-packages/mmcv/parallel/_functions.py: 这个文件需要修改一下, 否则报错:
if device.type == "cpu":
    AttributeError: 'int' object has no attribute 'type'

2. /home/yht/.conda/envs/sood-mcl/lib/python3.9/site-packages/mmcv/parallel/distributed.py: 这个文件需要修改一下, 否则报错:
AttributeError: 'MMDistributedDataParallel' object has no attribute '_use_replicated_tensor_module'

3.要同时输出dense_image_feature 和 image_feature, 可以修改下面这个文件里相对应的函数:
/home/yht/.cache/huggingface/modules/transformers_modules/qihoo360/fg-clip-large/19c2df7667052518ade09341652562b89b1332da/modeling_fgclip.py











目前的bug:
(0) 目前refine_head的梯度还是和其他部分的网络截断的
(1) scale_angle的问题:
/data/yht/code/sood-mcl/semi_mmrotate/models/rotated_dt_baseline.py 文件下rbb_decode函数里是否需要加上scale_angle
目前的初步判断是不需要加上(加上之后可视化出来的框位置不准确,去掉后位置就准确了)
(2) 多卡训练报错: AssertionError: loss log variables are different across GPUs!
目前怀疑是多卡训练时不同卡上的梯度类型不一致导致的, 原因是因为比如gpu0上没有正样本, 但是gpu1上有正样本(现象出现在无监督分支), 这样一来loss的计算方法就不一样了, 导致梯度类型不一致:
具体体现在/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_head.py 的328行和352行
当有正样本时,loss正常计算, 返回的loss的梯度类型是<MulBackward0>, 当没有正样本时, loss的梯度类型是<SumBackward0>

[尝试1]: 目前发现通过强制设置loss=0(无梯度),在debug的时候不报错, 正常训练的时候还是会报错
进一步在/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_ga_head.py: loss()
通过下面代码发现, gt的数量至少为1, 但是通过标签分配后num_pos的数量可能为0:
# 统计gt和num_pos的数量
if len(gt_labels)==1:
    print(gt_labels[0].shape, num_pos)

[尝试2]: 在/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_ga_head.py: loss():
添加valid_mask 有正样本时为1.0, 否则为0.0 并且初始化loss: loss_bbox = torch.zeros(1, device=flatten_points.device, requires_grad=True).squeeze()
最终打印出来loss的梯度类型一致, 但是还是报错 AssertionError: loss log variables are different across GPUs!, 怀疑可能不是梯度类型的问题, 而是变量不一致的问题

[尝试3]: 在/home/yht/.conda/envs/sood-mcl/lib/python3.9/site-packages/mmdet/models/detectors/base.py: _parse_losses():
注释掉:
            assert log_var_length == len(log_vars) * dist.get_world_size(), \
                'loss log variables are different across GPUs!\n' + message
by the way, 再调试这部分时, 还遇到一个问题:log_var_length本来=6, 但是经过dist.all_reduce(log_var_length)后, log_var_length会变成一个很随机的数, 比如2466942019529946246, 这是为什么
然后产生了新的报错(大致就是某部分带梯度的参数没更新):
RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not 
used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
making sure all `forward` function outputs participate in calculating loss. 
If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` 
function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
Parameter indices which did not receive grad for rank 0: 172 173 179
 In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
目前怀疑是debug时只是强制让不同gpu计算不同的loss, 而不是真正遇到num_pos==0时才计算不同loss, 因此打算从头完整训练一遍, 看是否还会报错
测试后还是报错, 怀疑不好在统一损失这块进行改动:
RuntimeError: NCCL communicator was aborted on rank 0.  Original reason for failure was: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1800691, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1805630 milliseconds before timing out.

[尝试4]: 
在: /data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_ga_head.py -> loss()
使用 dist.all_reduce()进行多卡之间的通信, 只要有一张卡上没有正样本, 则所有卡上的loss计算方式统一为无正样本的loss计算方式
现在貌似不会报错了


(3) 多卡训练报错(引入自监督分支产生的问题): pos = ((label >= 0) & (label < bg_class_ind)).nonzero().squeeze(1) (这个报错的地方很奇怪, 和下面找到的问题看似没有直接联系:)
"/data/yht/code/sood-mcl/semi_mmrotate/models/dense_heads/semi_rotated_baseline_fcos_ga_head.py" ->"/home/yht/.conda/envs/sood-mcl/lib/python3.9/site-packages/mmdet/models/losses/gfocal_loss.py" -> pos = ((label >= 0) & (label < bg_class_ind)).nonzero().squeeze(1)
一开始发现在自监督分支只要一加上 ss_loss_cnt即中心度损失, 一训练就会报上面的错误, 不加ss_loss_cnt训练到中途也会报这个错
后面发现直接导致的原因是是对特征执行旋转操作, 空白部分填充0, 在计算 F.binary_cross_entropy 时会报错, 如果填充一个不为0但是很小的错, 就不会报错了

再之后, 发现训练到中途依然会报这个错, 且是由于加上了ss_loss_box引起的(只加ss_loss_cnt和ss_loss_cls能完整的训练完) 目前还未发现是什么原因

20250603:
在 /home/yht/.conda/envs/sood-mcl/lib/python3.9/site-packages/mmdet/models/losses/gfocal_loss.py 下:
在pos = ((label >= 0) & (label < bg_class_ind)).nonzero().squeeze(1) 之前加上(重跑实验中, 不清楚是否有效) 

pred = torch.clamp(pred, min=1e-7, max=1-1e-7)  
score = torch.clamp(score, min=1e-7, max=1-1e-7) 
label = torch.clamp(label, min=0, max=pred.size(1))




